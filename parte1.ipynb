{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 20 pares de imágenes y máscaras.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando imágenes y máscaras: 0it [00:00, ?it/s]c:\\Users\\Usuario\\Desktop\\proyecto_investigacion\\env_pvc\\lib\\site-packages\\skimage\\feature\\texture.py:360: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n",
      "Cargando imágenes y máscaras: 7it [00:48,  7.97s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import sobel\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage.measure import moments_hu\n",
    "from skimage import img_as_ubyte\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff  # Importar tifffile para leer imágenes TIFF\n",
    "\n",
    "# Directorios de las imágenes y las máscaras\n",
    "directorio_satelital = \"roads/sat\"\n",
    "directorio_gt = \"roads/gt\"\n",
    "\n",
    "# Emparejar las imágenes con sus máscaras (suponiendo que tienen el mismo nombre)\n",
    "pares_imagenes_mascaras = list(zip(sorted(os.listdir(directorio_satelital)), sorted(os.listdir(directorio_gt))))\n",
    "\n",
    "# Por ejemplo, si las imágenes están en .tiff, ajusta la extensión\n",
    "pares_imagenes_mascaras = [\n",
    "    (img, img.replace('.tiff', '.tif'))  # Suponiendo que las máscaras tengan la extensión .tif\n",
    "    for img in sorted(os.listdir(directorio_satelital))\n",
    "]\n",
    "print(f\"Se encontraron {len(pares_imagenes_mascaras)} pares de imágenes y máscaras.\")\n",
    "\n",
    "# Nombre del archivo CSV\n",
    "csv_file = \"caracteristicas_imagenes.csv\"\n",
    "\n",
    "# Abrir el archivo CSV en modo escritura\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Escribir los encabezados del CSV\n",
    "    writer.writerow(['sobel', 'hog', 'lbp', 'hu_moments_1', 'hu_moments_2', 'hu_moments_3', 'hu_moments_4', 'hu_moments_5', 'hu_moments_6', 'hu_moments_7', 'etiqueta', 'imagen_idx'])\n",
    "    \n",
    "    # Cargar las imágenes y máscaras\n",
    "    for imagen_idx, (imagen_nombre, mascara_nombre) in tqdm(enumerate(pares_imagenes_mascaras), desc=\"Cargando imágenes y máscaras\"):\n",
    "        # Leer la imagen satelital\n",
    "        ruta_imagen = os.path.join(directorio_satelital, imagen_nombre)\n",
    "        imagen = imread(ruta_imagen)\n",
    "        \n",
    "        # Leer la máscara de ground truth (con tifffile para imágenes TIFF)\n",
    "        ruta_mascara = os.path.join(directorio_gt, mascara_nombre)\n",
    "        mascara = tiff.imread(ruta_mascara)\n",
    "        \n",
    "        # Asegurarse de que la máscara tenga valores 0 y 255\n",
    "        if np.max(mascara) <= 1:  # Si los valores están en el rango [0, 1]\n",
    "            print(\"Máscara en formato flotante [0, 1], convirtiendo a [0, 255]\")\n",
    "            mascara = (mascara * 255).astype(np.uint8)\n",
    "        elif np.max(mascara) > 255:  # Si la máscara tiene valores fuera del rango esperado\n",
    "            print(\"Máscara con valores fuera de rango [0, 255], normalizando\")\n",
    "            mascara = np.clip(mascara, 0, 255).astype(np.uint8)\n",
    "\n",
    "        # Convertir la imagen a escala de grises\n",
    "        imagen_gris = rgb2gray(imagen)\n",
    "        \n",
    "        # Extraer características Sobel para toda la imagen\n",
    "        sobel_features = sobel(imagen_gris)\n",
    "        \n",
    "        # Extraer características HOG para toda la imagen\n",
    "        hog_features, hog_image = hog(imagen_gris, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "\n",
    "        # Calcular LBP para la imagen en escala de grises\n",
    "        lbp = local_binary_pattern(imagen_gris, P=8, R=1, method='uniform')\n",
    "        \n",
    "        # Calcular los momentos de Hu\n",
    "        imagen_byte = img_as_ubyte(imagen_gris)\n",
    "        hu_moments = moments_hu(imagen_byte)\n",
    "        \n",
    "        # Identificar los píxeles de carretera y fondo\n",
    "        indices_carretera = np.where(mascara == 255)  # Carretera\n",
    "        indices_fondo = np.where(mascara == 0)      # Fondo\n",
    "\n",
    "        # Número de píxeles de fondo que queremos seleccionar\n",
    "        num_carretera = len(indices_carretera[0])\n",
    "        num_fondo = len(indices_fondo[0])\n",
    "\n",
    "        # Si los píxeles de fondo son más que los de carretera, hacer downsampling\n",
    "        if num_fondo > num_carretera:\n",
    "            downsampling_factor = num_fondo // num_carretera  # Ajustar el factor de downsampling\n",
    "            indices_fondo_downsampled = indices_fondo[0][::downsampling_factor]  # Reducir los píxeles de fondo\n",
    "        else:\n",
    "            indices_fondo_downsampled = indices_fondo[0]  # Mantener todos los píxeles de fondo si son menores o iguales a los de carretera\n",
    "\n",
    "        # Ahora aseguramos que los índices balanceados respeten las clases\n",
    "        indices_balanceados = np.concatenate(( \n",
    "            # Índices de carretera con etiqueta 255\n",
    "            np.array([255] * len(indices_carretera[0])), \n",
    "            # Índices de fondo balanceados con etiqueta 0\n",
    "            np.array([0] * len(indices_fondo_downsampled))\n",
    "        ))\n",
    "\n",
    "        # Combinar los índices y las etiquetas para las características\n",
    "        # Iterar sobre los índices balanceados\n",
    "        for idx_pixel, etiqueta in zip(np.concatenate((indices_carretera[0], indices_fondo_downsampled)), indices_balanceados):\n",
    "            i = idx_pixel // mascara.shape[1]  # Obtener la coordenada de la fila\n",
    "            j = idx_pixel % mascara.shape[1]   # Obtener la coordenada de la columna\n",
    "\n",
    "            # Extraer las características de Sobel para el píxel (i, j)\n",
    "            sobel_value = sobel_features[i, j]\n",
    "            \n",
    "            # Calcular el índice del vector de características HOG correspondiente al píxel (i, j)\n",
    "            hog_idx = (i // 16) * (imagen_gris.shape[1] // 16) + (j // 16)\n",
    "            hog_value = hog_features[hog_idx]\n",
    "            \n",
    "            # Obtener el valor de LBP para el píxel (i, j)\n",
    "            lbp_value = lbp[i, j]\n",
    "            \n",
    "            # Obtener los momentos de Hu (cada valor es un momento de Hu individual)\n",
    "            hu_value = hu_moments.tolist()  # Momentos de Hu como lista\n",
    "            \n",
    "            # Concatenar las características de Sobel, HOG, LBP y Hu Moments\n",
    "            caracteristicas_pixel = [sobel_value] + [hog_value] + [lbp_value] + hu_value\n",
    "            \n",
    "            # Escribir las características y la etiqueta en el CSV\n",
    "            writer.writerow(caracteristicas_pixel + [etiqueta, imagen_idx])  # Aquí se usa imagen_idx para la imagen actual\n",
    "\n",
    "# Verificar el contenido del CSV\n",
    "with open(csv_file, mode='r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i < 5:  # Imprimir las primeras 5 filas\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import sobel\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage.measure import moments_hu\n",
    "from skimage import img_as_ubyte\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el archivo CSV con las características y etiquetas\n",
    "data = pd.read_csv(\"caracteristicas_imagenes.csv\")\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = data[['sobel', 'hog', 'lbp', 'hu_moments_1', 'hu_moments_2', 'hu_moments_3', 'hu_moments_4', 'hu_moments_5', 'hu_moments_6', 'hu_moments_7']]\n",
    "y = data['etiqueta']\n",
    "\n",
    "# Dividir los datos en entrenamiento (80%), validación (10%) y prueba (10%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Entrenar el modelo Random Forest\n",
    "clf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42, verbose=2, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta de la imagen: roads/sat_test\\10078675_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10078675_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10228675_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10228675_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10228705_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10228705_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10228720_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10228720_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10228735_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10228735_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10228750_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10228750_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10378675_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10378675_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10378690_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10378690_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10378705_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10378705_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10378720_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10378720_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10378735_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10378735_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10378750_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10378750_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10378765_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10378765_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10528675_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10528675_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10528690_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10528690_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10528705_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10528705_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10528720_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10528720_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10528735_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10528735_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10528750_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10528750_15.tif\n",
      "Ruta de la imagen: roads/sat_test\\10528765_15.tiff\n",
      "Ruta de la máscara: roads/gt\\10528765_15.tif\n"
     ]
    }
   ],
   "source": [
    "for imagen_idx, (imagen_nombre, mascara_nombre) in enumerate(pares_imagenes_mascaras):\n",
    "    print(\"Ruta de la imagen:\", os.path.join(directorio_satelital, imagen_nombre))\n",
    "    print(\"Ruta de la máscara:\", os.path.join(directorio_gt, mascara_nombre))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo roads/sat_test\\10528765_15.tiff no existe\n"
     ]
    }
   ],
   "source": [
    "archivo_imagen = os.path.join(directorio_satelital, pares_imagenes_mascaras[imagen_idx][0])\n",
    "if not os.path.exists(archivo_imagen):\n",
    "    print(f\"El archivo {archivo_imagen} no existe\")\n",
    "else:\n",
    "    print(f\"El archivo {archivo_imagen} está presente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 255 is out of bounds for axis 0 with size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[245], line 16\u001b[0m\n\u001b[0;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124metiqueta\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Etiquetas (carretera o fondo)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Dividir los datos en entrenamiento (80%), validación (10%) y prueba (10%)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Dividir los datos balanceados\u001b[39;00m\n\u001b[0;32m     15\u001b[0m X_train, X_temp, y_train, y_temp, indices_train, indices_temp \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m---> 16\u001b[0m     X_balanceado, y_balanceado, \u001b[43mindices_imagenes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_balanceados\u001b[49m\u001b[43m]\u001b[49m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     19\u001b[0m X_val, X_test, y_val, y_test, indices_val, indices_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     20\u001b[0m     X_temp, y_temp, indices_temp, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTamaño de entrenamiento: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m muestras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 255 is out of bounds for axis 0 with size 20"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Cargar el CSV con las características\n",
    "df = pd.read_csv(\"caracteristicas_imagenes_pixel_a_pixel.csv\")\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = df[['R', 'G', 'B', 'sobel', 'hog']]  # Características (R, G, B, Sobel, HOG)\n",
    "y = df['etiqueta']  # Etiquetas (carretera o fondo)\n",
    "\n",
    "# Dividir los datos en entrenamiento (80%), validación (10%) y prueba (10%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Tamaño de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"Tamaño de validación: {X_val.shape[0]} muestras\")\n",
    "print(f\"Tamaño de prueba: {X_test.shape[0]} muestras\")\n",
    "\n",
    "\n",
    "\n",
    "# Entrenar el modelo Random Forest con los datos de entrenamiento\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1,verbose=2)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el rendimiento en el conjunto de validación\n",
    "y_val_pred = clf.predict(X_val)\n",
    "print(\"Informe de clasificación para el conjunto de validación:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Evaluar el rendimiento en el conjunto de prueba\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print(\"Informe de clasificación para el conjunto de prueba:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indices_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[240], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ejemplo con la última imagen de test:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m imagen_idx \u001b[38;5;241m=\u001b[39m \u001b[43mindices_test\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Puedes elegir cualquier índice del conjunto de test\u001b[39;00m\n\u001b[0;32m      3\u001b[0m ruta_imagen \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directorio_satelital, pares_imagenes_mascaras[imagen_idx][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      4\u001b[0m imagen \u001b[38;5;241m=\u001b[39m imread(ruta_imagen)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'indices_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Ejemplo con la última imagen de test:\n",
    "imagen_idx = indices_test[0]  # Puedes elegir cualquier índice del conjunto de test\n",
    "ruta_imagen = os.path.join(directorio_satelital, pares_imagenes_mascaras[imagen_idx][0])\n",
    "imagen = imread(ruta_imagen)\n",
    "\n",
    "# Generar la máscara predicha para la imagen\n",
    "pred_mask = modelo.predict(X[indices_test == imagen_idx]).reshape(imagen.shape[0], imagen.shape[1])\n",
    "\n",
    "# Mostrar la máscara predicha\n",
    "plt.imshow(pred_mask, cmap='gray')\n",
    "plt.title(\"Máscara Predicha\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pvc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
